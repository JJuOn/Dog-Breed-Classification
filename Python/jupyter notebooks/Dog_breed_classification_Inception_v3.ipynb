{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog breed classification_Inception_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CqX9cb9GBvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms, datasets, models\n",
        "import torch\n",
        "from torch import optim, cuda\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib..pyplot as plt\n",
        "from google.colab import files \n",
        "import json\n",
        "%matplotlib inline\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D__kAd9Q-7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded=files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    print('Upload {} : {}'.format(filename,len(uploaded[filename])))\n",
        "\n",
        "with open('./kaggle.json') as json_file:\n",
        "    api_token=json.loads(json_file.read())\n",
        "os.environ['KAGGLE_USERNAME']=api_token['username']\n",
        "os.environ['KAGGLE_KEY']=api_token['key']\n",
        "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset --unzip --force"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21cQesOhG6iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device=torch.device('cuda')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjYKStFAMn0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_image(breed,dog,data_dir):\n",
        "    img=plt.imread(os.path.join(data_dir,'images','Images',breed,dog)+'.jpg')\n",
        "    tree=ET.parse(os.path.join(data_dir,'annotations','Annotation',breed,dog))\n",
        "    xmin=int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n",
        "    xmax=int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n",
        "    ymin=int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n",
        "    ymax=int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n",
        "    img=img[ymin:ymax,xmin:xmax,:]\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NodVjFcpP1Rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir='.'\n",
        "breed_list=os.listdir(os.path.join(data_dir,'images','Images'))\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(4):\n",
        "    plt.subplot(421+(i*2))\n",
        "    breed=np.random.choice(breed_list)\n",
        "    dog=np.random.choice(os.listdir(os.path.join(data_dir,'annotations','Annotation',breed)))\n",
        "    img=plt.imread(os.path.join(data_dir,'images','Images',breed,dog)+'.jpg')\n",
        "    plt.imshow(img)\n",
        "    tree=ET.parse(os.path.join(data_dir,'annotations','Annotation',breed,dog))\n",
        "    xmin=int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n",
        "    xmax=int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n",
        "    ymin=int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n",
        "    ymax=int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n",
        "    plt.plot([xmin,xmax,xmax,xmin,xmin],[ymin,ymin,ymax,ymax,ymin])\n",
        "    crop_img=crop_image(breed,dog,data_dir)\n",
        "    plt.subplot(422+(i*2))\n",
        "    plt.imshow(crop_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuTqHwY56rPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 'data' not in os.listdir():\n",
        "    os.mkdir('data')\n",
        "for breed in breed_list:\n",
        "    os.mkdir('data/' + breed)\n",
        "print('Created {} folders to store cropped images of the different breeds.'.format(len(os.listdir('data'))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdH4-yEj62X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for breed in os.listdir('data'):\n",
        "    for file in os.listdir(os.path.join(data_dir,'annotations','Annotation', breed)):\n",
        "        img = Image.open(os.path.join(data_dir,'images','Images',breed, file)+'.jpg')\n",
        "        tree = ET.parse(os.path.join(data_dir,'annotations','Annotation',breed,file))\n",
        "        xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n",
        "        xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n",
        "        ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n",
        "        ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n",
        "        img = img.crop((xmin,ymin,xmax,ymax))\n",
        "        img = img.convert('RGB')\n",
        "        img.save('data/' + breed + '/' + file + '.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i67Bo0jX8CxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(315),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomResizedCrop(size=299),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=299),\n",
        "        transforms.CenterCrop(size=299),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhdLT1Hg9yt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "all_data = datasets.ImageFolder(root='data')\n",
        "train_data_len = int(len(all_data)*0.8)\n",
        "valid_data_len = int((len(all_data) - train_data_len)/2)\n",
        "test_data_len = int(len(all_data) - train_data_len - valid_data_len)\n",
        "train_data, val_data, test_data = random_split(all_data, [train_data_len, valid_data_len, test_data_len])\n",
        "train_data.dataset.transform = image_transforms['train']\n",
        "val_data.dataset.transform = image_transforms['test']\n",
        "test_data.dataset.transform = image_transforms['test']\n",
        "print(len(train_data), len(val_data), len(test_data))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8FaxgZobOZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainiter = iter(train_loader)\n",
        "features, labels = next(trainiter)\n",
        "print(features.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wElYnj2gSKGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.inception_v3(pretrained=True)\n",
        "model.aux_logits=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSotT-2GwmwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gClw9-p3wppE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 120\n",
        "n_inputs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(1024, n_classes),\n",
        "    nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOElQzfJwrai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.cuda()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3AJfFx4TYs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.class_to_idx=all_data.class_to_idx\n",
        "model.idx_to_class={\n",
        "    idx:class_ for class_,idx in model.class_to_idx.items()\n",
        "}\n",
        "list(model.idx_to_class.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGImrwtxUVkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,\n",
        "         criterion,\n",
        "         optimizer,\n",
        "         train_loader,\n",
        "         val_loader,\n",
        "         save_location,\n",
        "         early_stop=3,\n",
        "         n_epochs=20,\n",
        "         print_every=2):\n",
        "    valid_loss_min = np.Inf\n",
        "    stop_count = 0\n",
        "    valid_max_acc = 0\n",
        "    history = []\n",
        "    model.epochs = 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "\n",
        "        train_acc = 0\n",
        "        valid_acc = 0\n",
        "\n",
        "        model.train()\n",
        "        ii = 0\n",
        "\n",
        "        for data, label in train_loader:\n",
        "            ii += 1\n",
        "            data, label = data.cuda(), label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_tensor = pred.eq(label.data.view_as(pred))\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            train_acc += accuracy.item() * data.size(0)\n",
        "            if ii%10 == 0:\n",
        "                print(f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete.')\n",
        "\n",
        "        model.epochs += 1\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "\n",
        "            for data, label in val_loader:\n",
        "                data, label = data.cuda(), label.cuda()\n",
        "\n",
        "                output = model(data)\n",
        "                loss = criterion(output, label)\n",
        "                valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "                _, pred = torch.max(output, dim=1)\n",
        "                correct_tensor = pred.eq(label.data.view_as(pred))\n",
        "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "                valid_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            valid_loss = valid_loss / len(val_loader.dataset)\n",
        "\n",
        "            train_acc = train_acc / len(train_loader.dataset)\n",
        "            valid_acc = valid_acc / len(val_loader.dataset)\n",
        "\n",
        "            history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
        "\n",
        "            if (epoch + 1) % print_every == 0:\n",
        "                print(f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n",
        "                print(f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%')\n",
        "\n",
        "            if valid_loss < valid_loss_min:\n",
        "                torch.save({\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'idx_to_class': model.idx_to_class\n",
        "                }, save_location)\n",
        "                stop_count = 0\n",
        "                valid_loss_min = valid_loss\n",
        "                valid_best_acc = valid_acc\n",
        "                best_epoch = epoch\n",
        "\n",
        "            else:\n",
        "                stop_count += 1\n",
        "\n",
        "\n",
        "                if stop_count >= early_stop:\n",
        "                    print(f'\\nEarly Stopping Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n",
        "                    model.load_state_dict(torch.load(save_location)['state_dict'])\n",
        "                    model.optimizer = optimizer\n",
        "                    history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc','valid_acc'])\n",
        "                    return model, history\n",
        "\n",
        "    model.optimizer = optimizer\n",
        "    print(f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n",
        "\n",
        "    history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
        "    return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnQj5_hgZEsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, history = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    save_location='./dog_inception.pt',\n",
        "    early_stop=3,\n",
        "    n_epochs=30,\n",
        "    print_every=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEci9Eklw1K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHNPTS0Mw3E7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_acc = 0\n",
        "        for data, label in test_loader:\n",
        "            data, label = data.cuda(), label.cuda()\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_tensor = pred.eq(label.data.view_as(pred))\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            test_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "        test_acc = test_acc / len(test_loader.dataset)\n",
        "        return test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZhgtIB_w4js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('./dog_inception.pt')['state_dict'])\n",
        "test_acc = test(model.cuda(), test_loader, criterion)\n",
        "print(f'The model has achieved an accuracy of {100 * test_acc:.2f}% on the test dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23s7mmxYw6Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, test_loader, criterion):\n",
        "  \n",
        "    classes = []\n",
        "    acc_results = np.zeros(len(test_loader.dataset))\n",
        "    i = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, labels in test_loader:\n",
        "            data, labels = data.cuda(), labels.cuda()\n",
        "            output = model(data)\n",
        "\n",
        "            for pred, true in zip(output, labels):\n",
        "                _, pred = pred.unsqueeze(0).topk(1)\n",
        "                correct = pred.eq(true.unsqueeze(0))\n",
        "                acc_results[i] = correct.cpu()\n",
        "                classes.append(model.idx_to_class[true.item()][10:])\n",
        "                i+=1\n",
        "\n",
        "    results = pd.DataFrame({\n",
        "      'class': classes,\n",
        "      'results': acc_results    \n",
        "    })\n",
        "    results = results.groupby(classes).mean()\n",
        "\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mr2NyKFw70L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(evaluate(model, test_loader, criterion))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttRKRrJJwqyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5boRp42_xd1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img=Image.open('상원이네 강아지2.jpg')\n",
        "img=img.resize((299,299))\n",
        "plt.imshow(img)\n",
        "ToTensor_trans=transforms.ToTensor()\n",
        "Normalize_trans=transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "outputs=model(Normalize_trans(ToTensor_trans(img)).unsqueeze(0).cuda())\n",
        "outputs=F.softmax(outputs,dim=1)\n",
        "outputs,idx=outputs.unsqueeze(0).topk(3)\n",
        "for i,o in zip(idx.tolist()[0][0],outputs.tolist()[0][0]):\n",
        "    print('class:{}, probability:{:.4f}'.format(model.idx_to_class[i].split('-')[1],o*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcQEoq5M6EGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('dog_inception.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}